{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data initailizing....\n",
      "Memory usage of properties dataframe is : 355.856689453125  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  166.80782318115234  MB\n",
      "This is  46.875 % of the initial size\n",
      "Initial Separate_dt.....\n",
      "Initial Label_encoding.....\n",
      "Initial Process_csmcu.....\n",
      "Initial Set_cate_feat.....\n",
      "Initial Process_cano.....\n",
      "Initial encode_CB.....\n",
      "Initial Process_iterm.....\n",
      "Initial Process_acqic.....\n",
      "Initial Process_loctm.....\n",
      "Initial Process_txkey.....\n",
      "Initial Process_mchno.....\n",
      "Initial Process_locdt.....\n",
      "Initial flg_3dsmk.....\n",
      "Initial flbmk.....\n",
      "Initial Process_fre.....\n",
      "Initial Drop_feat.....\n",
      "Initial Return_record.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "Start_time = time.time()\n",
    "from Preprocessing import Processed_data\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from Tuning_parameter import Lgb_params\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import os \n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFECV\n",
    "#from Tuning_parameter import Lgb_params\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "Train_df      = Processed_data['Train_df'][:100]\n",
    "Test_df       = Processed_data['Test_df']\n",
    "Test_id       = Processed_data['Test_df']['txkey']\n",
    "#Record_list   = Processed_data['Record_list']\n",
    "Cate_feat     = Processed_data['Cate_feat']\n",
    "N_folds       = Processed_data['N_folds']\n",
    "Target        = 'fraud_ind'\n",
    "#Time          = datetime.today().strftime('%m-%d-%H-%M')\n",
    "\n",
    "def Cal_f1_score(True_y, Pre_y):\n",
    "    return f1_score(True_y, Pre_y)\n",
    "            \n",
    "def F1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def Split_group_kfolds():\n",
    "    Train_X = Train_df.drop(['fraud_ind'], axis=1)\n",
    "    Train_Y = Train_df['fraud_ind']\n",
    "    Folds  = GroupKFold(n_splits=3)\n",
    "    Splited_data = Folds.split(Train_X, Train_Y, groups=Train_X['Month']) \n",
    "    return Splited_data\n",
    "\n",
    "\n",
    "clf = lgb.LGBMClassifier( \n",
    "                #early_stopping_rounds = 10, \n",
    "                categorical_feature = Cate_feat, \n",
    "                #feval=F1_score, \n",
    "                #evals_result={},     \n",
    "                num_leaves =  31,\n",
    "                min_child_samples =  79,\n",
    "                objective = 'binary',\n",
    "                max_depth = -1,\n",
    "                learning_rate =  0.025,\n",
    "                boosting_type = 'gbdt',\n",
    "                #\"subsample\": 0.8,\n",
    "                bagging_seed = 42,\n",
    "                #\"verbosity\": -1,\n",
    "                #'reg_alpha': 0.3,\n",
    "                #'reg_lambda': 0.3,\n",
    "                #'colsample_bytree': 0.8,\n",
    "                num_boost_round = 1, \n",
    "                verbose_eval = 100,\n",
    "                #'scale_pos_weight' : 700,\n",
    "                #num_threads  =4\n",
    "                )\n",
    "\n",
    "rfecv = RFECV(estimator=clf, step=5, cv=3, scoring='f1_macro')\n",
    "\n",
    "Exluded_cols = ['fraud_ind', 'txkey', 'Month']\n",
    "All_Features = [Feat for Feat in Train_df.columns if Feat not in Exluded_cols]\n",
    "\n",
    "rfecv.fit(Train_df[All_Features].values, Train_df[Target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df      = Processed_data['Train_df'][:100]\n",
    "Test_df       = Processed_data['Test_df']\n",
    "Test_id       = Processed_data['Test_df']['txkey']\n",
    "#Record_list   = Processed_data['Record_list']\n",
    "Cate_feat     = Processed_data['Cate_feat']\n",
    "N_folds       = Processed_data['N_folds']\n",
    "Target        = 'fraud_ind'\n",
    "#Time          = datetime.today().strftime('%m-%d-%H-%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cal_f1_score(True_y, Pre_y):\n",
    "    return f1_score(True_y, Pre_y)\n",
    "            \n",
    "def F1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def Split_group_kfolds():\n",
    "    Train_X = Train_df.drop(['fraud_ind'], axis=1)\n",
    "    Train_Y = Train_df['fraud_ind']\n",
    "    Folds  = GroupKFold(n_splits=3)\n",
    "    Splited_data = Folds.split(Train_X, Train_Y, groups=Train_X['Month']) \n",
    "    return Splited_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Splited_data = Split_group_kfolds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier( \n",
    "                #early_stopping_rounds = 10, \n",
    "                categorical_feature = Cate_feat, \n",
    "                #feval=F1_score, \n",
    "                #evals_result={},     \n",
    "                num_leaves =  31,\n",
    "                min_child_samples =  79,\n",
    "                objective = 'binary',\n",
    "                max_depth = -1,\n",
    "                learning_rate =  0.025,\n",
    "                boosting_type = 'gbdt',\n",
    "                #\"subsample\": 0.8,\n",
    "                bagging_seed = 42,\n",
    "                #\"verbosity\": -1,\n",
    "                #'reg_alpha': 0.3,\n",
    "                #'reg_lambda': 0.3,\n",
    "                #'colsample_bytree': 0.8,\n",
    "                num_boost_round = 1, \n",
    "                verbose_eval = 100,\n",
    "                #'scale_pos_weight' : 700,\n",
    "                #num_threads  =4\n",
    "                )\n",
    "\n",
    "rfecv = RFECV(estimator=clf, step=5, cv=3, scoring='f1_macro')\n",
    "\n",
    "Exluded_cols = ['fraud_ind', 'txkey', 'Month']\n",
    "All_Features = [Feat for Feat in Train_df.columns if Feat not in Exluded_cols]\n",
    "\n",
    "rfecv.fit(Train_df[All_Features].values, Train_df[Target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=clf, step=5, cv=3, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exluded_cols = ['fraud_ind', 'txkey', 'Month']\n",
    "All_Features = [Feat for Feat in Train_df.columns if Feat not in Exluded_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.fit(Train_df[All_Features].values, Train_df[Target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df[All_Features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
