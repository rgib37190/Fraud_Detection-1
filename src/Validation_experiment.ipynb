{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import gc\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFECV\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#from Tuning_parameter import Lgb_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('training_set_prep.csv')\n",
    "test = pd.read_csv('testing_set_prep.csv')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reduce_mem(df):\n",
    "    start_mem_usg = df.memory_usage().sum() / (1024*1024)\n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    for col in df.keys():\n",
    "        if df[col].dtype == int:\n",
    "            Max = df[col].max()\n",
    "            Min = df[col].min()\n",
    "            if -128 < Min and Max < 127:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif -32768 < Min and Max < 32767:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif -2147483648 < Min and Max < 2147483647:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.int)\n",
    "        elif df[col].dtype == float:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "        else:\n",
    "            continue\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return df\n",
    "\n",
    "def Process_fre(df, cols):\n",
    "    print('Initial Process_fre.....')\n",
    "    for col in cols:\n",
    "        vc = df[col].value_counts(dropna=True, normalize=True).to_dict()\n",
    "        vc[-1] = -1\n",
    "        new_col = col+'_freq'\n",
    "        df[col] = df[col].map(vc)\n",
    "        df[col] = df[col].astype('float32')\n",
    "\n",
    "    return df\n",
    "\n",
    "def Separate_dt(df1):   \n",
    "    df1['Month'] = 0\n",
    "    df1.loc[df1['locdt'] < 121, 'Month'] = 4\n",
    "    df1.loc[df1['locdt'] < 91, 'Month']  = 3\n",
    "    df1.loc[df1['locdt'] < 61, 'Month']  = 2\n",
    "    df1.loc[df1['locdt'] < 31, 'Month'] = 1\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def Split_group_kfolds(df):\n",
    "    Train_X = df.drop(['fraud_ind'], axis=1)\n",
    "    Train_Y = df['fraud_ind']\n",
    "    Folds  = GroupKFold(n_splits=3)\n",
    "    Splited_data = Folds.split(Train_X, Train_Y, groups=Train_X['Month']) \n",
    "    return Splited_data\n",
    "\n",
    "def Cal_f1_score(True_y, Pre_y):\n",
    "    return f1_score(True_y, Pre_y)\n",
    "\n",
    "def F1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 673.3983001708984  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  238.01154708862305  MB\n",
      "This is  35.344839306576695 % of the initial size\n",
      "Memory usage of properties dataframe is : 183.37189483642578  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  65.54748821258545  MB\n",
      "This is  35.74565680910705 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "train = Separate_dt(train)\n",
    "train = Reduce_mem(train)\n",
    "test = Reduce_mem(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Feature :  42\n"
     ]
    }
   ],
   "source": [
    "Splited_data = Split_group_kfolds(train)\n",
    "Excluded_cols = ['bacno','cano','locdt', 'loctm','OOOO_tag','scity','cano_max_locdt','cano_min_locdt',\n",
    "            'cano_stocn_nunique_locdt','cano_stocn_diff_locdt','cano_stocn_min_diff_locdt', 'txkey',\n",
    "            'cano_stocn_min_locdt','cano_stocn_max_locdt', 'fraud_ind', 'Month', 'is_test']\n",
    "\n",
    "All_Features = [Feat for Feat in train.columns if Feat not in Excluded_cols]\n",
    "print('Total Feature : ', len(All_Features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'bagging_freq': 4,\n",
    "#         'num_boost_round' : 100, \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Process_fre.....\n",
      "Initial Process_fre.....\n"
     ]
    }
   ],
   "source": [
    "Cate_feat = ['contp','mchno','acqic','mcc','insfg','stocn','stscd','iterm',\n",
    "             'ovrlt','flbmk','hcefg','flg_3dsmk','ecfg','etymd',\n",
    "             'cano_diff','change_signal','cano_diff_change_signal','stocn_scity']\n",
    "\n",
    "# train[Cate_feat] = train[Cate_feat].astype('category')\n",
    "# test[Cate_feat] = test[Cate_feat].astype('category')\n",
    "train = Process_fre(train, Cate_feat)\n",
    "test  = Process_fre(test, Cate_feat)\n",
    "for col in ['flbmk', 'flg_3dsmk', '14_variables_count']:\n",
    "    train[col].fillna(-999, inplace = True)\n",
    "    test[col].fillna(-999, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$1 fold\n",
      "Hold out  1 month\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's binary_logloss: 0.0339617\ttraining's f1: 0.404617\tvalid_1's binary_logloss: 0.0327042\tvalid_1's f1: 0.421497\n",
      "[40]\ttraining's binary_logloss: 0.0280788\ttraining's f1: 0.547163\tvalid_1's binary_logloss: 0.0270394\tvalid_1's f1: 0.518628\n",
      "[60]\ttraining's binary_logloss: 0.0253716\ttraining's f1: 0.601903\tvalid_1's binary_logloss: 0.0249318\tvalid_1's f1: 0.554385\n",
      "[80]\ttraining's binary_logloss: 0.0237126\ttraining's f1: 0.634247\tvalid_1's binary_logloss: 0.0238089\tvalid_1's f1: 0.574836\n",
      "[100]\ttraining's binary_logloss: 0.0225746\ttraining's f1: 0.65831\tvalid_1's binary_logloss: 0.0233004\tvalid_1's f1: 0.587832\n",
      "[120]\ttraining's binary_logloss: 0.0216979\ttraining's f1: 0.668941\tvalid_1's binary_logloss: 0.023489\tvalid_1's f1: 0.590605\n",
      "[140]\ttraining's binary_logloss: 0.0212896\ttraining's f1: 0.673023\tvalid_1's binary_logloss: 0.0237984\tvalid_1's f1: 0.590673\n",
      "[160]\ttraining's binary_logloss: 0.0239646\ttraining's f1: 0.673961\tvalid_1's binary_logloss: 0.0312442\tvalid_1's f1: 0.589534\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's binary_logloss: 0.0218781\ttraining's f1: 0.667664\tvalid_1's binary_logloss: 0.023237\tvalid_1's f1: 0.592658\n",
      "$2 fold\n",
      "Hold out  3 month\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's binary_logloss: 0.0306615\ttraining's f1: 0.530342\tvalid_1's binary_logloss: 0.0423273\tvalid_1's f1: 0.370388\n",
      "[40]\ttraining's binary_logloss: 0.0246312\ttraining's f1: 0.658378\tvalid_1's binary_logloss: 0.042679\tvalid_1's f1: 0.419431\n",
      "[60]\ttraining's binary_logloss: 0.0220388\ttraining's f1: 0.696812\tvalid_1's binary_logloss: 0.0420663\tvalid_1's f1: 0.442736\n",
      "[80]\ttraining's binary_logloss: 0.0205689\ttraining's f1: 0.717639\tvalid_1's binary_logloss: 0.0408185\tvalid_1's f1: 0.454586\n",
      "[100]\ttraining's binary_logloss: 0.0194483\ttraining's f1: 0.729522\tvalid_1's binary_logloss: 0.0399014\tvalid_1's f1: 0.456239\n",
      "[120]\ttraining's binary_logloss: 0.0185689\ttraining's f1: 0.744994\tvalid_1's binary_logloss: 0.03931\tvalid_1's f1: 0.461391\n",
      "[140]\ttraining's binary_logloss: 0.0180864\ttraining's f1: 0.752068\tvalid_1's binary_logloss: 0.0390747\tvalid_1's f1: 0.466389\n",
      "[160]\ttraining's binary_logloss: 0.0176144\ttraining's f1: 0.759167\tvalid_1's binary_logloss: 0.039083\tvalid_1's f1: 0.469815\n",
      "[180]\ttraining's binary_logloss: 0.0172398\ttraining's f1: 0.763856\tvalid_1's binary_logloss: 0.0390836\tvalid_1's f1: 0.471545\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's binary_logloss: 0.0180837\ttraining's f1: 0.751491\tvalid_1's binary_logloss: 0.0387109\tvalid_1's f1: 0.467241\n",
      "$3 fold\n",
      "Hold out  2 month\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's binary_logloss: 0.0284984\ttraining's f1: 0.482788\tvalid_1's binary_logloss: 0.0421124\tvalid_1's f1: 0.424076\n",
      "[40]\ttraining's binary_logloss: 0.0234268\ttraining's f1: 0.573176\tvalid_1's binary_logloss: 0.0363219\tvalid_1's f1: 0.499314\n",
      "[60]\ttraining's binary_logloss: 0.0211526\ttraining's f1: 0.614317\tvalid_1's binary_logloss: 0.0342229\tvalid_1's f1: 0.535758\n",
      "[80]\ttraining's binary_logloss: 0.0198442\ttraining's f1: 0.639905\tvalid_1's binary_logloss: 0.0331405\tvalid_1's f1: 0.550427\n",
      "[100]\ttraining's binary_logloss: 0.0189495\ttraining's f1: 0.650306\tvalid_1's binary_logloss: 0.032937\tvalid_1's f1: 0.553578\n",
      "[120]\ttraining's binary_logloss: 0.0181572\ttraining's f1: 0.666465\tvalid_1's binary_logloss: 0.0326304\tvalid_1's f1: 0.559398\n",
      "[140]\ttraining's binary_logloss: 0.0180845\ttraining's f1: 0.674959\tvalid_1's binary_logloss: 0.0326987\tvalid_1's f1: 0.563636\n",
      "[160]\ttraining's binary_logloss: 0.0172953\ttraining's f1: 0.684455\tvalid_1's binary_logloss: 0.0326982\tvalid_1's f1: 0.566702\n",
      "[180]\ttraining's binary_logloss: 0.0167967\ttraining's f1: 0.69671\tvalid_1's binary_logloss: 0.032785\tvalid_1's f1: 0.566957\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's binary_logloss: 0.0177681\ttraining's f1: 0.673857\tvalid_1's binary_logloss: 0.0325623\tvalid_1's f1: 0.563632\n",
      " F1 = 0.540965710286914\n"
     ]
    }
   ],
   "source": [
    "X = train[All_Features +['Month']]\n",
    "Y = train['fraud_ind']\n",
    "\n",
    "Oof = np.zeros(len(train))\n",
    "Preds = np.zeros(len(test))\n",
    "\n",
    "for fold_n, (train_idx, valid_idx) in enumerate(Splited_data):\n",
    "    print(f'${fold_n+1} fold')\n",
    "    X_trn, X_val= X[All_Features].iloc[train_idx], X[All_Features].iloc[valid_idx]\n",
    "    Y_trn, Y_val = Y.iloc[train_idx], Y.iloc[valid_idx]\n",
    "    print('Hold out ', X.iloc[valid_idx]['Month'].iloc[0], 'month')\n",
    "    #X_trn, Y_trn = self.Under_sample(X_trn, Y_trn)\n",
    "    \n",
    "\n",
    "\n",
    "    trn_data = lgb.Dataset(X_trn, label=Y_trn)\n",
    "    val_data = lgb.Dataset(X_val, label=Y_val)\n",
    "    \n",
    "    clf = lgb.train(params= Lgb_params, train_set= trn_data, \n",
    "                                    valid_sets= [trn_data, val_data],\n",
    "                                    num_boost_round = 300, \n",
    "                                    verbose_eval = 20, \n",
    "                                    early_stopping_rounds = 50, \n",
    "                                    categorical_feature = Cate_feat, \n",
    "                                    feval=F1_score, \n",
    "                                    evals_result={})\n",
    "    \n",
    "    Y_pred_val = clf.predict(X_val)\n",
    "    Oof[valid_idx] = Y_pred_val\n",
    "    Preds += clf.predict(test[All_Features]) / 3\n",
    "    \n",
    "Oof = np.round(Oof)\n",
    "Preds = np.round(Preds)\n",
    "Score = Cal_f1_score(Y, Oof)\n",
    "print(f' F1 = {Cal_f1_score(Y, Oof)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Label_encoding(df, feat_list):\n",
    "    print('Initial Label_encoding.....')\n",
    "    #insfg、ecfg、ovrlt、flbmk、flg_3dsmk\n",
    "    le = LabelEncoder()\n",
    "    for feat in feat_list:\n",
    "        df[feat] = le.fit_transform(df[feat].astype(str))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Label_encoding.....\n",
      "Initial Label_encoding.....\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "rm = gc.collect()\n",
    "del rm\n",
    "train['is_test'] = 0 \n",
    "test['is_test'] = 1 \n",
    "traub = Label_encoding(train, ['ecfg', 'flbmk', 'flg_3dsmk', 'insfg', 'ovrlt'])\n",
    "test = Label_encoding(test, ['ecfg', 'flbmk', 'flg_3dsmk', 'insfg', 'ovrlt'])\n",
    "\n",
    "\n",
    "All = pd.concat([train, test], axis=0)\n",
    "All = All\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6089952924715116"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train) / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold\n",
      "Fold 1 count :  1554761\n",
      "0.5262733828090991\n",
      "Fold 2 count :  1554761\n",
      "0.5382353466338712\n",
      "Fold 3 count :  1554762\n",
      "0.5392184374773679\n",
      "Fold 4 count :  1554762\n",
      "0.539290165322523\n",
      "Fold 5 count :  1554762\n",
      "0.5384123630993248\n",
      "Final score :  0.5362588578281333\n",
      "Skfold\n",
      "Fold 1 count :  1554761\n",
      "0.5377905235329946\n",
      "Fold 2 count :  1554761\n",
      "0.5270553655390395\n",
      "Fold 3 count :  1554762\n",
      "0.5381526093156817\n",
      "Fold 4 count :  1554762\n",
      "0.5370804174485158\n",
      "Fold 5 count :  1554762\n",
      "0.5255982499995886\n",
      "Final score :  0.5331354233245313\n"
     ]
    }
   ],
   "source": [
    "Excluded_cols = ['bacno','cano','locdt', 'loctm','OOOO_tag','scity','cano_max_locdt','cano_min_locdt',\n",
    "            'cano_stocn_nunique_locdt','cano_stocn_diff_locdt','cano_stocn_min_diff_locdt', 'txkey',\n",
    "            'cano_stocn_min_locdt','cano_stocn_max_locdt', 'fraud_ind', 'Month', 'is_test']\n",
    "All_Features = [Feat for Feat in train.columns if Feat not in Excluded_cols]\n",
    "\n",
    "kfs = {'Kfold' :  KFold(n_splits = 5, shuffle = True, random_state = 42) , \n",
    "       'Skfold' : StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)}\n",
    "\n",
    "eval_preds = np.zeros(len(All))\n",
    "probs = np.zeros(len(All))\n",
    "\n",
    "for name, mehtod in kfs.items():\n",
    "    print(name)\n",
    "    for fold, (train_index, test_index) in enumerate(mehtod.split(All, All['is_test'])):\n",
    "        x0, x1 = All[All_Features].iloc[train_index], All[All_Features].iloc[test_index]\n",
    "        y0, y1 = All['is_test'].iloc[train_index], All['is_test'].iloc[test_index]        \n",
    "        print(f'Fold {fold+1} count : ', x0.shape[0])\n",
    "    \n",
    "        xgb_params = {\n",
    "            'learning_rate': 0.05, 'max_depth': 4,'subsample': 0.9,\n",
    "            'objective': 'binary:logistic', 'eval_metric' : 'auc',\n",
    "            'n_estimators':100, 'scale_pos_weight' : 3.6\n",
    "            }   \n",
    "        clf = xgb.XGBClassifier(**xgb_params, seed = 10, verbosity=1)  \n",
    "    \n",
    "        \n",
    "        clf.fit(x0, y0, eval_set=[(x1, y1)],\n",
    "               eval_metric='logloss', verbose=False,early_stopping_rounds=10)\n",
    "                \n",
    "        prval = clf.predict(x1)\n",
    "        probs[test_index] = clf.predict_proba(x1)[:,1]\n",
    "        print(roc_auc_score(y1,prval))\n",
    "        eval_preds[test_index] = prval\n",
    "    print('Final score : ', roc_auc_score(All['is_test'], eval_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# train      = train\n",
    "# Test_df       = test\n",
    "N_folds       = 3\n",
    "Target        = 'fraud_ind'\n",
    "\n",
    "\n",
    "def RFE(clf):\n",
    "    rfecv = RFECV(estimator=clf, step=1, cv = Split_group_kfolds(train), verbose=2, n_jobs = -1, scoring = 'f1')\n",
    "    rfecv.fit(train[All_Features], train[Target])\n",
    "    sel_features = [f for f, s in zip(All_Features, rfecv.support_) if s]\n",
    "    print('\\n The selected features are {}:'.format(sel_features))\n",
    "    print(len(sel_features))\n",
    "    \n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.xlabel('Number of features ')\n",
    "    plt.ylabel('Cross-validation score (F1_score)')\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1) , rfecv.grid_scores_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Month'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-742ae8734013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-91ebb87513fa>\u001b[0m in \u001b[0;36mRFE\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mrfecv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplit_group_kfolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAll_Features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msel_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAll_Features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4b2a4cbbfe59>\u001b[0m in \u001b[0;36mSplit_group_kfolds\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mTrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fraud_ind'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mFolds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mGroupKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mSplited_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSplited_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Month'"
     ]
    }
   ],
   "source": [
    "Lgb = lgb.LGBMClassifier( \n",
    "            objective = 'binary',\n",
    "            max_depth =  -1,\n",
    "            learning_rate = 0.05,\n",
    "            boosting_type = \"gbdt\",\n",
    "            bagging_freq = 4,\n",
    "#         'num_boost_round' : 100, \n",
    "        categorical_feature = Cate_feat\n",
    "                )\n",
    "\n",
    "RFE(Lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.025, 0.001],\n",
    "    \n",
    "#     'n_estimators': [20, 40]\n",
    "    \n",
    "}\n",
    "clf = lgb.train(params= Lgb_params, train_set= trn_data, \n",
    "                valid_sets= [trn_data, val_data],\n",
    "                num_boost_round = 5, \n",
    "                verbose_eval = 100, \n",
    "                early_stopping_rounds = 50, \n",
    "                categorical_feature = Cate_feat, \n",
    "                feval=F1_score, \n",
    "                evals_result={})\n",
    "\n",
    "gbm = GridSearchCV(estimator, param_grid, cv=3)\n",
    "gbm.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
